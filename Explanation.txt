Project Submission
Submission Instructions
Required: 
    In the respective "problem_1.py" files, include at least 3 test cases for each solution.
    For each test case, write the function call with the input you want to test and print it to the console".
    On the next line, comment out the output you expect to see from that function call. 
    At least 2 of these must be edge cases, testing inputs such as null values, empty inputs, unusually large values, etc.
    
    Write up an explanation for each question in a single separate text file, PDF or markdown called "explanation_1.md".
    Your paragraph should not be a detailed walkthrough of the code you provided, 
    but provide your reasoning behind decisions made in the code. 
    For example, why did you use that data structure? 
    You also need to explain the efficiency (time and space) of your solution.


1. explanation_1.md
    For the LRU Cache problem we start by declaring our classes LRU Cache and Node. This sets the structure for our algorithm. An LRU Cache can be solved by utilizing two data structures, a doubly linked list and a hashmap because of the hashmap's O(1) constant time lookup and doubly linked lists O(N) removal and insertion. Both are low in space complexity as well at O(N) for the entire algorithm. The approximate Big O run time efficiency of this solution is calculated below: 

    1. get() and set() - O(1)
    2. remove() and insert() - O(N) 
    3. total = O(N)

    First we declare our Node class variables including key, value, next and previous and set them to None. Our LRU Cache class variables include our hashmap, capacity, head, tail, head.next and tail.previous. We make sure the head and tail point to each other initially. 

    Our algorithm is made up of 4 instance methods or functions, two for our hashmap and two for our doubly linked list. 

    Our get method checks if node is in the hashmap, if it is that is called our "Cache Hit!" which we then create a node to hold the value at that key in the hashmap. We "refresh" the cache remove the node, and adding it back and returing the value. If our node is not in the cache that is a "Cache Miss!" and we return -1.

    Our set method also checks if node is in hashmap, if it is then we remove the least recently used node, assign a new node to hold that value and we refresh the cache, inserting our new node to the linked list and also adding it to our hashmap. If it is not in our hashmap then we assign a new node and add it to our hashmap. If the length of our hashmap is greater than our cache capacity, then we assign our node to head.next and remove the least recently used node and finally delete that node key from our hashmap.

    Our remove and insert functions 



2. The Huffman Coding algorithm is utilizing a Binary Tree, a Queue, a MinHeap, and a Hashmap. Breaking down this problem into sub problems is really the only way to accomplish the goal here because of the complexity in creating the tree itself and finally retrieving the leafs with ordered paths and thus, encoded data. The time and space complexity is approximated below which I believe was the most efficient given our constraints. 

1. Binary Tree - O(1)
2. Queue - O()
3. MinHeap - O()
4. DFS - O()
5. Encoded
6. Decoded
7. result: 

    In this algorithm we start with creating our Node and Binary Tree classes since we know these two components are the main vehicles of our program allowing us to iterate and traverse our tree. I learned an important point of including __str__ and __eq__ dunder methods to our Node class so that we could work with operators within our tree values and to be able to print out our objects. I utilized basic helper instance methods like get_left_child() and set_left_child() for more efficiency in other functions. 

    Our Binary Tree class included our hashmap and a basic get_root instance method. Going into more detail on additional instance methods we will start with relevant frequencies. This function starts the process of mapping our string to our dictionary and includes a frequency value for each number of times that character appears in our string. I included the build tree helper function to start builing our tree with these values collecting in our hashmap.

    A basic Binary Tree implementation would not be useful here as I learned because this tree needs to be built in a certain way unlike the way a BST is created where left nodes are less than parent and vice versa.

    Here, we have to add the values from the two lowest frequencies and then merge the two nodes into one parent node that will include a total of both frequencies. The only option here was to use a Queue data structure to handle the 


